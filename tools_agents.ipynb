{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6f6456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Arxiv--Research\n",
    "## Tools creation\n",
    "from langchain_community.tools import ArxivQueryRun,WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper,ArxivAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3ec59fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia in .\\venv\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: beautifulsoup4 in .\\venv\\lib\\site-packages (from wikipedia) (4.13.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in .\\venv\\lib\\site-packages (from wikipedia) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in .\\venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.6.15)\n",
      "Requirement already satisfied: soupsieve>1.2 in .\\venv\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in .\\venv\\lib\\site-packages (from beautifulsoup4->wikipedia) (4.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df21a2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Used the inbuilt tool of wikipedia\n",
    "api_wrapper_wiki=WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=250)\n",
    "wiki=WikipediaQueryRun(api_wrapper=api_wrapper_wiki)\n",
    "wiki.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26d0bc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: arxiv in .\\venv\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: feedparser~=6.0.10 in .\\venv\\lib\\site-packages (from arxiv) (6.0.11)\n",
      "Requirement already satisfied: requests~=2.32.0 in .\\venv\\lib\\site-packages (from arxiv) (2.32.4)\n",
      "Requirement already satisfied: sgmllib3k in .\\venv\\lib\\site-packages (from feedparser~=6.0.10->arxiv) (1.0.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in .\\venv\\lib\\site-packages (from requests~=2.32.0->arxiv) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\venv\\lib\\site-packages (from requests~=2.32.0->arxiv) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\venv\\lib\\site-packages (from requests~=2.32.0->arxiv) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\venv\\lib\\site-packages (from requests~=2.32.0->arxiv) (2025.6.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "745bc329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv\n"
     ]
    }
   ],
   "source": [
    "api_wrapper_arxiv=ArxivAPIWrapper(top_k_results=1,doc_content_chars_max=250)\n",
    "arxiv=ArxivQueryRun(api_wrapper=api_wrapper_arxiv)\n",
    "print(arxiv.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87bdbbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[wiki,arxiv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5681ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##custom tools[RAG tools]\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc3b1e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ad5d6eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Using cached faiss_cpu-1.11.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in .\\venv\\lib\\site-packages (from faiss-cpu) (2.3.1)\n",
      "Requirement already satisfied: packaging in .\\venv\\lib\\site-packages (from faiss-cpu) (24.2)\n",
      "Using cached faiss_cpu-1.11.0-cp312-cp312-win_amd64.whl (15.0 MB)\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "570813d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000029AD7AEB050>, search_kwargs={})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader=WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
    "docs=loader.load()\n",
    "documents=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200).split_documents(docs)\n",
    "vectordb=FAISS.from_documents(documents,OllamaEmbeddings())\n",
    "retriever=vectordb.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d5d0667a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langsmith-search'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool=create_retriever_tool(retriever,\"langsmith-search\",\"Search any information about Langsmith \")\n",
    "\n",
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3588b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[wiki,arxiv,retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d35644c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\searchengine\\\\venv\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=250)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=250)),\n",
       " Tool(name='langsmith-search', description='Search any information about Langsmith ', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x0000029AF816E980>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000029AD7AEB050>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x0000029AF816ECA0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000029AD7AEB050>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d299659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_groq\n",
      "  Downloading langchain_groq-0.3.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.67 in .\\venv\\lib\\site-packages (from langchain_groq) (0.3.67)\n",
      "Collecting groq<1,>=0.29.0 (from langchain_groq)\n",
      "  Using cached groq-0.29.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in .\\venv\\lib\\site-packages (from groq<1,>=0.29.0->langchain_groq) (4.9.0)\n",
      "Collecting distro<2,>=1.7.0 (from groq<1,>=0.29.0->langchain_groq)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in .\\venv\\lib\\site-packages (from groq<1,>=0.29.0->langchain_groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in .\\venv\\lib\\site-packages (from groq<1,>=0.29.0->langchain_groq) (2.11.7)\n",
      "Requirement already satisfied: sniffio in .\\venv\\lib\\site-packages (from groq<1,>=0.29.0->langchain_groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in .\\venv\\lib\\site-packages (from groq<1,>=0.29.0->langchain_groq) (4.14.0)\n",
      "Requirement already satisfied: idna>=2.8 in .\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.29.0->langchain_groq) (3.10)\n",
      "Requirement already satisfied: certifi in .\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.29.0->langchain_groq) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in .\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.29.0->langchain_groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in .\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.29.0->langchain_groq) (0.16.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in .\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.67->langchain_groq) (0.4.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in .\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.67->langchain_groq) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in .\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.67->langchain_groq) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in .\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.67->langchain_groq) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in .\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.67->langchain_groq) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in .\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.67->langchain_groq) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in .\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.29.0->langchain_groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in .\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.29.0->langchain_groq) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in .\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.29.0->langchain_groq) (0.4.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in .\\venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.67->langchain_groq) (3.10.18)\n",
      "Requirement already satisfied: requests<3,>=2 in .\\venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.67->langchain_groq) (2.32.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in .\\venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.67->langchain_groq) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in .\\venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.67->langchain_groq) (0.23.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in .\\venv\\lib\\site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.67->langchain_groq) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\venv\\lib\\site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.67->langchain_groq) (2.5.0)\n",
      "Downloading langchain_groq-0.3.5-py3-none-any.whl (15 kB)\n",
      "Using cached groq-0.29.0-py3-none-any.whl (130 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: distro, groq, langchain_groq\n",
      "\n",
      "   ---------------------------------------- 0/3 [distro]\n",
      "   ------------- -------------------------- 1/3 [groq]\n",
      "   ------------- -------------------------- 1/3 [groq]\n",
      "   ------------- -------------------------- 1/3 [groq]\n",
      "   ------------- -------------------------- 1/3 [groq]\n",
      "   ------------- -------------------------- 1/3 [groq]\n",
      "   ------------- -------------------------- 1/3 [groq]\n",
      "   ------------- -------------------------- 1/3 [groq]\n",
      "   ------------- -------------------------- 1/3 [groq]\n",
      "   -------------------------- ------------- 2/3 [langchain_groq]\n",
      "   ---------------------------------------- 3/3 [langchain_groq]\n",
      "\n",
      "Successfully installed distro-1.9.0 groq-0.29.0 langchain_groq-0.3.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb94fdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Run all this tools with Agents and LLM Models\n",
    "\n",
    "## Tools, LLM-->AgentExecutor\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "# import openai\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "# openai.api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm=ChatGroq(groq_api_key=groq_api_key,model_name=\"Llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ee3772d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Prompt Template\n",
    "from langchain import hub\n",
    "prompt=hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cbbdf905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000029AD5B4D9E0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000029AD5B4D9E0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000029AD7937C80>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000029AD7934FB0>, model_name='Llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'langsmith-search', 'description': 'Search any information about Langsmith ', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Agents\n",
    "from langchain.agents import create_openai_tools_agent\n",
    "agent=create_openai_tools_agent(llm,tools,prompt)\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "59d6fac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000029AD5B4D9E0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000029AD5B4D9E0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000029AD7937C80>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000029AD7934FB0>, model_name='Llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'langsmith-search', 'description': 'Search any information about Langsmith ', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\searchengine\\\\venv\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=250)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=250)), Tool(name='langsmith-search', description='Search any information about Langsmith ', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x0000029AF816E980>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000029AD7AEB050>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x0000029AF816ECA0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000029AD7AEB050>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Agent Executer\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executor=AgentExecutor(agent=agent,tools=tools,verbose=True)\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "22a1914a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith-search` with `{'query': 'Langsmith'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mGet started with LangSmith | 🦜️🛠️ LangSmith\n",
      "\n",
      "Get started by creating your first prompt.\n",
      "Iterate on models and prompts using the Playground.\n",
      "Manage prompts programmatically in your application.\n",
      "Was this page helpful?You can leave detailed feedback on GitHub.NextQuick StartObservabilityEvalsPrompt EngineeringCommunityLangChain ForumTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2025 LangChain, Inc.\n",
      "\n",
      "Skip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!API ReferenceRESTPythonJS/TSSearchRegionUSEUGo to AppGet StartedObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referenceGet StartedOn this pageGet started with LangSmith\n",
      "LangSmith is a platform for building production-grade LLM applications.\n",
      "It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence.\n",
      "ObservabilityAnalyze traces in LangSmith and configure metrics, dashboards, alerts based on these.EvalsEvaluate your application over production traffic — score application performance and get human feedback on your data.Prompt EngineeringIterate on prompts, with automatic version control and collaboration features.\n",
      "\n",
      "LangSmith + LangChain OSSLangSmith is framework-agnostic — it can be used with or without LangChain's open source frameworks langchain and langgraph.If you are using either of these, you can enable LangSmith tracing with a single environment variable.\n",
      "For more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\n",
      "Observability​\n",
      "Observability is important for any software application, but especially so for LLM applications. LLMs are non-deterministic by nature, meaning they can produce unexpected results. This makes them trickier than normal to debug.\n",
      "This is where LangSmith can help! LangSmith has LLM-native observability, allowing you to get meaningful insights from your application. LangSmith’s observability features have you covered throughout all stages of application development - from prototyping, to beta testing, to production.\u001b[0m\u001b[32;1m\u001b[1;3mBased on the output from the tool call, it seems that Langsmith is a platform for building production-grade LLM (Large Language Model) applications. It provides features for observability, evaluation, and prompt engineering to help developers ship their applications quickly and with confidence.\n",
      "\n",
      "Langsmith offers several key features, including:\n",
      "\n",
      "1. Observability: Langsmith allows developers to analyze traces and configure metrics, dashboards, and alerts to monitor their application's performance.\n",
      "2. Evals: Langsmith enables developers to evaluate their application over production traffic and score its performance, as well as receive human feedback on their data.\n",
      "3. Prompt Engineering: Langsmith provides automatic version control and collaboration features for iterating on prompts.\n",
      "\n",
      "Langsmith is also framework-agnostic, meaning it can be used with or without Langchain's open-source frameworks, Langchain and Langgraph.\n",
      "\n",
      "Langsmith emphasizes the importance of observability in LLM applications, which are non-deterministic by nature and can produce unexpected results. Langsmith's observability features aim to provide meaningful insights throughout all stages of application development, from prototyping to production.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about Langsmith',\n",
       " 'output': \"Based on the output from the tool call, it seems that Langsmith is a platform for building production-grade LLM (Large Language Model) applications. It provides features for observability, evaluation, and prompt engineering to help developers ship their applications quickly and with confidence.\\n\\nLangsmith offers several key features, including:\\n\\n1. Observability: Langsmith allows developers to analyze traces and configure metrics, dashboards, and alerts to monitor their application's performance.\\n2. Evals: Langsmith enables developers to evaluate their application over production traffic and score its performance, as well as receive human feedback on their data.\\n3. Prompt Engineering: Langsmith provides automatic version control and collaboration features for iterating on prompts.\\n\\nLangsmith is also framework-agnostic, meaning it can be used with or without Langchain's open-source frameworks, Langchain and Langgraph.\\n\\nLangsmith emphasizes the importance of observability in LLM applications, which are non-deterministic by nature and can produce unexpected results. Langsmith's observability features aim to provide meaningful insights throughout all stages of application development, from prototyping to production.\"}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"Tell me about Langsmith\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fbb8c75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Machine learning'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalise to unseen data, and thus perform tasks wit\u001b[0m\u001b[32;1m\u001b[1;3mBased on the result from the \"wikipedia\" tool, I can provide a more detailed response.\n",
      "\n",
      "Machine learning is a fascinating field that has become increasingly important in recent years. It involves developing algorithms that can learn from data and improve their performance over time. This is in contrast to traditional programming, where the rules and logic are hardcoded.\n",
      "\n",
      "There are several types of machine learning, including supervised and unsupervised learning. Supervised learning involves training an algorithm on labeled data, where the correct output is already known. The algorithm learns to predict the output for new, unseen data. Unsupervised learning involves training an algorithm on unlabeled data, and it must find patterns or structure in the data on its own.\n",
      "\n",
      "Some common applications of machine learning include image and speech recognition, natural language processing, and recommender systems. It's also used in self-driving cars, medical diagnosis, and financial forecasting, among many other areas.\n",
      "\n",
      "I hope this provides a good overview of machine learning!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is machine learning',\n",
       " 'output': 'Based on the result from the \"wikipedia\" tool, I can provide a more detailed response.\\n\\nMachine learning is a fascinating field that has become increasingly important in recent years. It involves developing algorithms that can learn from data and improve their performance over time. This is in contrast to traditional programming, where the rules and logic are hardcoded.\\n\\nThere are several types of machine learning, including supervised and unsupervised learning. Supervised learning involves training an algorithm on labeled data, where the correct output is already known. The algorithm learns to predict the output for new, unseen data. Unsupervised learning involves training an algorithm on unlabeled data, and it must find patterns or structure in the data on its own.\\n\\nSome common applications of machine learning include image and speech recognition, natural language processing, and recommender systems. It\\'s also used in self-driving cars, medical diagnosis, and financial forecasting, among many other areas.\\n\\nI hope this provides a good overview of machine learning!'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"What is machine learning\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0b59100a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': '1706.03762'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPublished: 2023-08-02\n",
      "Title: Attention Is All You Need\n",
      "Authors: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin\n",
      "Summary: The dominant sequence transduction models are based on c\u001b[0m\u001b[32;1m\u001b[1;3mIt appears that the paper \"1706.03762\" is actually titled \"Attention Is All You Need\" and it's about sequence transduction models.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"What's the paper 1706.03762 about?\",\n",
       " 'output': 'It appears that the paper \"1706.03762\" is actually titled \"Attention Is All You Need\" and it\\'s about sequence transduction models.'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"What's the paper 1706.03762 about?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f685397",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
